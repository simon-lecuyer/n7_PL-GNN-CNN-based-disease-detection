# ğŸ“Š Pipeline de DonnÃ©es - Guide Complet

## Vue d'ensemble

Cette pipeline transforme les simulations brutes WaterberryFarms en datasets PyTorch prÃªts pour l'entraÃ®nement CNN et GNN.

```
Simulations     PrÃ©traitement      Datasets        EntraÃ®nement
  (brutes)         (images)        PyTorch           (modÃ¨les)
     â”‚                â”‚                â”‚                  â”‚
     â–¼                â–¼                â–¼                  â–¼
generate_data â†’ preprocess_data â†’ create_datasets â†’ train_*.py
```

## ğŸ”„ Ã‰tapes de la Pipeline

### 1ï¸âƒ£ GÃ©nÃ©ration de Simulations

**Script:** `scripts/generate_data.py`

GÃ©nÃ¨re des simulations de propagation de maladies avec WaterberryFarms.

```bash
python scripts/generate_data.py \
    --num_simulations 50 \
    --grid_size 100 \
    --timesteps 200 \
    --model_type epidemic \
    --p_transmission 0.2 \
    --seed 42
```

**Sortie:** `data/simulations/generation_TIMESTAMP/`
- Images brutes (PNG)
- Graphes bruts (NPY)
- MÃ©tadonnÃ©es complÃ¨tes

---

### 2ï¸âƒ£ PrÃ©traitement des DonnÃ©es

**Script:** `scripts/preprocess_data.py`

Transforme les donnÃ©es brutes en formats optimisÃ©s pour CNN et GNN.

#### Usage de base

```bash
python scripts/preprocess_data.py \
    --input data/simulations/generation_20260204_173051 \
    --output data/processed \
    --target_size 64 \
    --normalize \
    --crop
```

#### ParamÃ¨tres importants

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| `--input` | - | Dossier de gÃ©nÃ©ration (requis) |
| `--output` | `data/processed` | Dossier de sortie |
| `--target_size` | 64 | Taille des images CNN (64x64) |
| `--crop` | False | Crop automatique sur zones infectÃ©es |
| `--crop_margin` | 5 | Marge autour du crop |
| `--normalize` | False | Normaliser en [0, 1] |
| `--standardize` | False | Standardiser (mean=0, std=1) |
| `--add_spatial_features` | False | Ajouter coordonnÃ©es aux features GNN |
| `--min_infection` | 0.0 | Seuil minimum pour garder timestep |
| `--formats` | `cnn gnn` | Formats Ã  gÃ©nÃ©rer |

#### Optimisations CNN

**Crop automatique:**
```bash
--crop --crop_margin 10
```
â†’ Se concentre sur les zones avec infection, rÃ©duit le bruit

**Normalisation:**
```bash
--normalize  # [0, 1]
# ou
--standardize  # mean=0, std=1
```

#### Optimisations GNN

**Features spatiales:**
```bash
--add_spatial_features
```
â†’ Ajoute (x, y) normalisÃ©es aux features des nÅ“uds

**Distance personnalisÃ©e:**
```bash
--edge_threshold 2.0
```
â†’ Connecte nÅ“uds Ã  distance â‰¤ 2.0 (dÃ©faut: 4-voisinage)

#### Exemples

**CNN optimisÃ©:**
```bash
python scripts/preprocess_data.py \
    --input data/simulations/generation_XXX \
    --formats cnn \
    --target_size 64 \
    --crop \
    --normalize
```

**GNN avec features enrichies:**
```bash
python scripts/preprocess_data.py \
    --input data/simulations/generation_XXX \
    --formats gnn \
    --add_spatial_features \
    --normalize
```

**Les deux formats (comparaison):**
```bash
python scripts/preprocess_data.py \
    --input data/simulations/generation_XXX \
    --formats cnn gnn \
    --target_size 64 \
    --crop \
    --normalize \
    --add_spatial_features
```

**Sortie:** `data/processed/processed_TIMESTAMP/`
```
processed_20260209_165358/
â”œâ”€â”€ preprocessing_metadata.json
â”œâ”€â”€ cnn/
â”‚   â”œâ”€â”€ sim_0000/
â”‚   â”‚   â”œâ”€â”€ t_0000.npy  # {'data': array(64,64), 'crop_bbox': ...}
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ sim_0001/
â””â”€â”€ gnn/
    â”œâ”€â”€ sim_0000/
    â”‚   â”œâ”€â”€ t_0000.npy  # {'nodes': ..., 'edges': ..., 'node_features': ...}
    â”‚   â””â”€â”€ ...
    â””â”€â”€ sim_0001/
```

---

### 3ï¸âƒ£ CrÃ©ation des Datasets PyTorch

**Script:** `scripts/create_datasets.py`

CrÃ©e les splits train/val/test avec stratification.

#### Usage de base

```bash
python scripts/create_datasets.py \
    --input data/processed/processed_20260209_165358 \
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15 \
    --stratify_by simulation \
    --seed 42
```

#### ParamÃ¨tres de split

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| `--train_ratio` | 0.7 | Proportion train (70%) |
| `--val_ratio` | 0.15 | Proportion validation (15%) |
| `--test_ratio` | 0.15 | Proportion test (15%) |
| `--stratify_by` | `simulation` | Stratification (simulation/infection_level/timestep/none) |
| `--seed` | 42 | Seed pour reproductibilitÃ© |

#### SÃ©quences temporelles

Pour modÃ¨les temporels (LSTM, Transformer):

```bash
python scripts/create_datasets.py \
    --input data/processed/processed_XXX \
    --create_sequences \
    --sequence_length 5 \
    --sequence_stride 1
```

**Sortie:** `data/processed/processed_XXX/datasets/`
```
datasets/
â”œâ”€â”€ dataset_metadata.json
â”œâ”€â”€ cnn/
â”‚   â”œâ”€â”€ train.json      # Liste des fichiers train
â”‚   â”œâ”€â”€ train.pkl       # Version pickle (rapide)
â”‚   â”œâ”€â”€ val.json
â”‚   â”œâ”€â”€ val.pkl
â”‚   â”œâ”€â”€ test.json
â”‚   â””â”€â”€ test.pkl
â””â”€â”€ gnn/
    â”œâ”€â”€ train.json
    â”œâ”€â”€ val.json
    â””â”€â”€ test.json
```

---

### 4ï¸âƒ£ Utilisation dans PyTorch

**Module:** `utils/datasets.py`

#### Dataset simple

```python
from utils.datasets import DiseaseDetectionDataset, get_dataloader
from torchvision import transforms

# CNN
train_loader = get_dataloader(
    "data/processed/processed_XXX/datasets/cnn/train.json",
    format="cnn",
    batch_size=32,
    shuffle=True,
    transform=transforms.Compose([
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
)

for images in train_loader:
    # images: torch.Tensor [batch, 1, 64, 64]
    pass

# GNN
train_loader = get_dataloader(
    "data/processed/processed_XXX/datasets/gnn/train.json",
    format="gnn",
    batch_size=16,
    shuffle=True
)

for graphs in train_loader:
    # graphs: list of dicts avec 'nodes', 'edges', 'node_features'
    pass
```

#### Dataset temporel

```python
from utils.datasets import TemporalDiseaseDataset

dataset = TemporalDiseaseDataset(
    "data/processed/processed_XXX/datasets/cnn/train_seq5.json",
    format="cnn"
)

for sequence, target, metadata in dataset:
    # sequence: list de 5 tensors [1, 64, 64]
    # target: tensor [1, 64, 64]
    pass
```

---

## ğŸ“‹ Pipeline ComplÃ¨te - Exemple

### GÃ©nÃ©rer 100 simulations pour production

```bash
# 1. GÃ©nÃ©ration
python scripts/generate_data.py \
    --num_simulations 100 \
    --grid_size 100 \
    --timesteps 200 \
    --model_type epidemic \
    --p_transmission 0.25 \
    --infection_duration 7 \
    --seed 42

# 2. PrÃ©traitement (optimisÃ© pour comparaison CNN/GNN)
python scripts/preprocess_data.py \
    --input data/simulations/generation_TIMESTAMP \
    --output data/processed \
    --name disease_dataset_v1 \
    --target_size 128 \
    --crop \
    --crop_margin 10 \
    --normalize \
    --add_spatial_features \
    --formats cnn gnn

# 3. CrÃ©ation datasets
python scripts/create_datasets.py \
    --input data/processed/disease_dataset_v1 \
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15 \
    --stratify_by simulation \
    --seed 42

# 4. EntraÃ®nement (TODO)
python scripts/train_cnn.py --dataset data/processed/disease_dataset_v1/datasets/cnn
python scripts/train_gnn.py --dataset data/processed/disease_dataset_v1/datasets/gnn
```

---

## ğŸ¯ StratÃ©gies de Comparaison CNN vs GNN

### Garantir la comparabilitÃ©

Pour comparer Ã©quitablement CNN et GNN:

1. **MÃªme source de donnÃ©es**
   ```bash
   --formats cnn gnn  # GÃ©nÃ©rer les deux simultanÃ©ment
   ```

2. **MÃªme split train/val/test**
   ```bash
   --stratify_by simulation --seed 42  # Split identique
   ```

3. **Normalisation cohÃ©rente**
   ```bash
   --normalize  # MÃªme normalisation pour CNN et GNN
   ```

4. **VÃ©rifier les statistiques**
   ```json
   // preprocessing_metadata.json
   "statistics": {
     "cnn": {"mean": 0.758, "std": 0.339},
     "gnn": {"avg_nodes": 900, "feature_dim": 3}
   }
   ```

### MÃ©triques Ã  comparer

- PrÃ©cision de dÃ©tection
- Temps d'infÃ©rence
- Robustesse au bruit
- GÃ©nÃ©ralisation (test set)
- EfficacitÃ© mÃ©moire

---

## ğŸ” VÃ©rification et Debug

### VÃ©rifier le prÃ©traitement

```python
import numpy as np
import matplotlib.pyplot as plt

# Charger un Ã©chantillon CNN
data = np.load("data/processed/processed_XXX/cnn/sim_0000/t_0010.npy", 
               allow_pickle=True).item()
plt.imshow(data['data'], cmap='viridis')
plt.title(f"Timestep {data['timestep']}")
plt.show()

# Charger un Ã©chantillon GNN
data = np.load("data/processed/processed_XXX/gnn/sim_0000/t_0010.npy",
               allow_pickle=True).item()
print(f"Nodes: {data['nodes'].shape}")
print(f"Edges: {data['edges'].shape}")
print(f"Features: {data['node_features'].shape}")
```

### VÃ©rifier les splits

```python
import json

with open("data/processed/processed_XXX/datasets/cnn/train.json") as f:
    train = json.load(f)

print(f"Train samples: {train['num_samples']}")
print(f"Simulations: {set(s['sim_id'] for s in train['samples'])}")
print(f"Timestep range: [{min(s['timestep'] for s in train['samples'])}, "
      f"{max(s['timestep'] for s in train['samples'])}]")
```

---

## ğŸ“ Structure Finale

```
data/
â”œâ”€â”€ simulations/                    # DonnÃ©es brutes
â”‚   â””â”€â”€ generation_20260204_173051/
â”‚       â”œâ”€â”€ generation_metadata.json
â”‚       â””â”€â”€ sim_XXXX/
â”‚           â”œâ”€â”€ metadata.json
â”‚           â”œâ”€â”€ images/
â”‚           â””â”€â”€ graphs/
â”‚
â””â”€â”€ processed/                      # DonnÃ©es preprocessÃ©es
    â””â”€â”€ processed_20260209_165358/
        â”œâ”€â”€ preprocessing_metadata.json
        â”œâ”€â”€ cnn/
        â”‚   â””â”€â”€ sim_XXXX/
        â”‚       â””â”€â”€ t_XXXX.npy      # {'data': array, 'crop_bbox': ...}
        â”œâ”€â”€ gnn/
        â”‚   â””â”€â”€ sim_XXXX/
        â”‚       â””â”€â”€ t_XXXX.npy      # {'nodes': ..., 'edges': ..., ...}
        â””â”€â”€ datasets/
            â”œâ”€â”€ dataset_metadata.json
            â”œâ”€â”€ cnn/
            â”‚   â”œâ”€â”€ train.json      # Splits pour CNN
            â”‚   â”œâ”€â”€ val.json
            â”‚   â””â”€â”€ test.json
            â””â”€â”€ gnn/
                â”œâ”€â”€ train.json      # Splits pour GNN
                â”œâ”€â”€ val.json
                â””â”€â”€ test.json
```

---

## âš¡ Commandes Rapides

```bash
# Pipeline complÃ¨te en 3 commandes
python scripts/generate_data.py --num_simulations 50 --grid_size 100 --timesteps 200
python scripts/preprocess_data.py --input data/simulations/generation_XXX --crop --normalize --add_spatial_features
python scripts/create_datasets.py --input data/processed/processed_XXX --stratify_by simulation

# VÃ©rifier les rÃ©sultats
ls data/processed/processed_XXX/datasets/cnn/
ls data/processed/processed_XXX/datasets/gnn/
```

---

## ğŸ“š Ressources

- **Scripts:** [scripts/](../scripts/)
- **Utils:** [utils/datasets.py](../utils/datasets.py)
- **Exemples:** [test/](../test/)
